{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '-1' #disble gpu\n",
    "\n",
    "def get_text_data():\n",
    "    sentences=[]\n",
    "    file_name=\"cleaned_assamese_text.txt\"\n",
    "    file=open(file_name,'r')\n",
    "    file_sentences=file.read().split(',')\n",
    "    sentences+=file_sentences\n",
    "    file.close()\n",
    "    sentences=list(filter(None,sentences))\n",
    "    return sentences\n",
    "\n",
    "sentences=get_text_data()\n",
    "\n",
    "#maxlen = len(max(sentences))\n",
    "maxlen=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-02 12:37:11.424814: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-02 12:37:12.361581: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.0/lib64:/usr/local/cuda-11.7/lib64::/home/yuvrajtalukdar/miniconda3/envs/miniproject/lib/\n",
      "2023-03-02 12:37:12.361928: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.0/lib64:/usr/local/cuda-11.7/lib64::/home/yuvrajtalukdar/miniconda3/envs/miniproject/lib/\n",
      "2023-03-02 12:37:12.361935: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-03-02 12:37:13.750568: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-02 12:37:13.884081: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-02 12:37:13.884364: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-02 12:37:13.884766: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-02 12:37:13.885246: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-02 12:37:13.885366: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-02 12:37:13.885490: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-02 12:37:14.539052: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-02 12:37:14.539211: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-02 12:37:14.539326: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-02 12:37:14.539422: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2107 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "def custom_standardization(input_string):\n",
    "    sentence = tf.strings.lower(input_string)\n",
    "    #sentence = tf.strings.regex_replace(sentence, \"\\n\", \" \")\n",
    "    return sentence\n",
    "\n",
    "vectorize_layer = TextVectorization(\n",
    "    standardize = custom_standardization,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=maxlen + 1,\n",
    ")\n",
    "\n",
    "vectorize_layer.adapt(sentences)\n",
    "vocab = vectorize_layer.get_vocabulary()\n",
    "vocab_size = len(vocab)\n",
    "index_lookup = dict(zip(range(len(vocab)), vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-02 12:37:27.539533: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 155379200 exceeds 10% of free system memory.\n",
      "2023-03-02 12:37:27.708615: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 155379200 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "import keras_nlp\n",
    "from tensorflow import keras\n",
    "\n",
    "embed_dim = 128\n",
    "num_heads = 4\n",
    "\n",
    "def create_model2(no_of_decoder=1):\n",
    "    inputs = keras.layers.Input(shape=(maxlen,), dtype=tf.int32)\n",
    "    x = keras_nlp.layers.TokenAndPositionEmbedding(vocab_size, maxlen, embed_dim)(inputs)\n",
    "    for i in range(4):\n",
    "        x = keras_nlp.layers.TransformerDecoder(intermediate_dim=embed_dim*2, num_heads=num_heads,dropout=0.5)(x)\n",
    "    do = keras.layers.Dropout(0.4)(x)\n",
    "    outputs = keras.layers.Dense(vocab_size, activation='softmax')(do)\n",
    "    \n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(\n",
    "        optimizer=\"adam\", \n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=[keras_nlp.metrics.Perplexity(), 'accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model=create_model2(4)\n",
    "\n",
    "model.load_weights(\"pd_plaintext_transformer.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_token(logits):\n",
    "        logits, indices = tf.math.top_k(logits, k=5, sorted=True)\n",
    "        indices = np.asarray(indices).astype(\"int32\")\n",
    "        preds = keras.activations.softmax(tf.expand_dims(logits, 0))[0]\n",
    "        preds = np.asarray(preds).astype(\"float32\")\n",
    "        return np.random.choice(indices, p=preds)\n",
    "\n",
    "def generate_text(prompt, response_length=50):\n",
    "    decoded_sample = prompt\n",
    "    for i in range(response_length-1):\n",
    "        tokenized_prompt = vectorize_layer([decoded_sample])[:, :-1]\n",
    "        predictions = model.predict([tokenized_prompt], verbose=0)\n",
    "        sample_index = len(decoded_sample.strip().split())-1\n",
    "        #print(sample_index)\n",
    "        \n",
    "        if sample_index>=len(predictions[0]):\n",
    "            continue\n",
    "\n",
    "        sampled_token = sample_token(predictions[0][sample_index])\n",
    "        sampled_token = index_lookup[sampled_token]\n",
    "        decoded_sample += \" \" + sampled_token\n",
    "    return decoded_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'লাচিত বৰফুকনে মোগলৰ বিৰুদ্ধে যুদ্ধ কৰি অসমখন বচাইছিল। আৰু নিজৰ জীৱন আৰম্ভ কৰিছিল আৰু তেওঁৰ মতে তেওঁ কয়   আৰু আন আন এক গুৰুত্বপূৰ্ণ আৰু তেওঁৰ পত্নী আছিল। কিন্তু তেওঁৰ পত্নী আৰু পুত্ৰ সন্তান আছিল। তেওঁক ভাৰতৰ প্ৰথম অৱস্থাত তেওঁ এজন ব্যক্তিয়ে তেওঁক নিজৰ জীৱন যাপন কৰে বুলি বৰ্ণনা কৰিছিল। সেই সময়ত'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text='লাচিত বৰফুকনে মোগলৰ বিৰুদ্ধে যুদ্ধ কৰি অসমখন বচাইছিল।'\n",
    "print(len(text))\n",
    "generate_text(text,response_length=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "miniproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b18115e74db522ea4edaf3f03801a60154dbaca70e4a91a6289c29c6971e06fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
